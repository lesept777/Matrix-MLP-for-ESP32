Verbose level : 1
Creating network:
4 layers
	Input layer: 2 neurons
	Hidden layer 1: 30 neurons
	Hidden layer 2: 20 neurons
	Output layer: 4 neurons
Processing dataset
Sum of ratios is not 100% (600.0%): setting ratios to 0.67, 0.17, 0.17
Dataset split in: 200 train + 50 validation + 50 test data
Normalizing the dataset (option 1)
Setting activations:
	Layer 0: activation SIGMOID
	Layer 1: activation SIGMOID
	Layer 2: activation SOFTMAX
Setting hyperparameters:
- Learning rate = 0.200000
- Momentum      = 0.500000
Network's size:
	Layer 0: 60 weights, 30 biases
	Layer 1: 600 weights, 20 biases
	Layer 2: 80 weights, 4 biases
	Total number of synapses: 794 (i.e. weights + biases)
---------------------------
Heuristics parameters:
- Init with random weights
- Select best weights at init
- Slightly change weights if needed
- Variable learning rate (log scale from 10^-0.699 to 10^-4.000)
- Random variable Sigmoid gain between 0.500 and 2.000
- Force weights less than 0.150 to zero
- Gradient clipping (clip value 0.750)
---------------------------
Batch size = 10
Stopping if error < 0.030

Running optimization
Shuffling dataset...
Creating a new network
Searching best starting weights
--> Found better weights (error = 1.5455)
--> Found better weights (error = 1.5303)
--> Found better weights (error = 1.5000)
--> Found better weights (error = 1.3939)
--> Found better weights (error = 1.3636)
--> Found better weights (error = 1.2879)
Estimated maximum duration : 882.00 s for 100 epochs

Epoch 1 	Average error :   1.2700 (validation   1.3800)
....
Epoch 6 	Average error :   1.1800 (validation   1.3800)
Epoch 7 	Average error :   1.1600 (validation   1.3800)
Epoch 8 	Average error :   1.1150 (validation   1.3800)
Epoch 9 	Average error :   1.0450 (validation   1.3800)
Epoch 10 	Average error :   1.0400 (validation   1.3800)
Epoch 11 	Average error :   1.0100 (validation   1.2600)
Epoch 12 	Average error :   0.9150 (validation   1.0600)
Epoch 13 	Average error :   0.8200 (validation   0.9800)
Epoch 14 	Average error :   0.7300 (validation   0.8200)
Epoch 15 	Average error :   0.6750 (validation   0.6800)
Epoch 16 	Average error :   0.5650 (validation   0.4200)
Epoch 17 	Average error :   0.5050 (validation   0.3800)
Epoch 18 	Average error :   0.3600 (validation   0.3000)
Epoch 19 	Average error :   0.3000 (validation   0.1400)
Epoch 20 	Average error :   0.2850 (validation   0.1200)
.
Epoch 22 	Average error :   0.2450 (validation   0.0800)
Epoch 23 	Average error :   0.2050 (validation   0.0800)
Epoch 24 	Average error :   0.1950 (validation   0.0600)
.
Epoch 26 	Average error :   0.1850 (validation   0.1000)
Epoch 27 	Average error :   0.1750 (validation   0.1000)
Epoch 28 	Average error :   0.1650 (validation   0.1000)
Epoch 29 	Average error :   0.1550 (validation   0.1000)
..........Restoring last saved weights
........Heuristics: changing Sigmoid gain to 0.85

Epoch 48 	Average error :   0.1400 (validation   0.0600)
....
Epoch 53 	Average error :   0.1350 (validation   0.0600)
....
Epoch 58 	Average error :   0.1300 (validation   0.0200)
..
Epoch 61 	Average error :   0.1150 (validation   0.0200)
..........Restoring last saved weights
...........Restoring last saved weights
Random change to weights (amplitude 10.0%)
....
Epoch 87 	Average error :   0.1100 (validation   0.0200)
..........Restoring last saved weights
...
Timer : 620.44 s

Evaluation on test data (50 samples):
 - Minimum value of error :   0.0000
 - Maximum value of error :   1.0000
 - Mean value of error    :   0.0400
 - Std deviation of error :   0.1960
 - L1 norm of error       :   1.0000
 - L2 norm of error       :   1.4142
Confusion matrix:
TR/PR    0    1    2    3  (Recall)
  0 :   14    0    0    0  (100.0%)
  1 :    0    7    0    0  (100.0%)
  2 :    0    0   18    2  ( 90.0%)
  3 :    0    0    0    9  (100.0%)
Prec:  100% 100% 100%  82% -> 96.0%
Low precision prediction :  12.0%
Average test error  :   0.0400
Saving network in file /SectorNetwork.txt

Verification:
Validation  0: expected 0, prediction 0 -->OK
Validation  1: expected 1, prediction 1 -->OK
Validation  2: expected 0, prediction 1 -->NOK
Validation  3: expected 0, prediction 0 -->OK
Validation  4: expected 0, prediction 0 -->OK
Validation  5: expected 0, prediction 0 -->OK
Validation  6: expected 3, prediction 3 -->OK
Validation  7: expected 3, prediction 3 -->OK
Validation  8: expected 0, prediction 0 -->OK
Validation  9: expected 2, prediction 3 -->NOK
Validation 10: expected 2, prediction 2 -->OK
Validation 11: expected 3, prediction 3 -->OK
Validation 12: expected 1, prediction 1 -->OK
Validation 13: expected 3, prediction 3 -->OK
Validation 14: expected 0, prediction 0 -->OK
Validation 15: expected 0, prediction 0 -->OK
Validation 16: expected 2, prediction 2 -->OK
Validation 17: expected 3, prediction 3 -->OK
Validation 18: expected 1, prediction 1 -->OK
Validation 19: expected 3, prediction 3 -->OK
Mean classification rate : 90.00 %

---------------------------
Network has 4 layers:
Layer 0: 2 neurons
Layer 1: 30 neurons, activation SIGMOID, 60 weights, 30 biases
Layer 2: 20 neurons, activation SIGMOID, 600 weights, 20 biases
Layer 3: 4 neurons, activation SOFTMAX, 80 weights, 4 biases
Total number of synapses: 794 (i.e. weights + biases)
Average L1 norm of synapses: 0.442
Average L2 norm of synapses: 0.415
Average value of synapses:   -0.034
Standard dev. of synapses:   0.910
Ratio of synapses greater than 1:   15.24 %
Ratio of synapses less than 1:      28.34 %
Ratio of synapses less than 0.1:     0.00 %
Ratio of synapses less than 0.01:    0.00 %
Ratio of synapses less than 0.001:   0.00 %
Ratio of synapses less than 0.0001: 56.42 % (sparsity)

Final learning rate: 0.000
Final Sigmoid gain : 0.850
Final momentum     : 0.500
---------------------------
