Verbose level : 1
Creating network:
4 layers
	Input layer: 2 neurons
	Hidden layer 1: 30 neurons
	Hidden layer 2: 20 neurons
	Output layer: 4 neurons
Processing dataset
Setting activations:
	Layer 0: activation SIGMOID
	Layer 1: activation SIGMOID
	Layer 2: activation SOFTMAX
Setting hyperparameters:
 - Learning rate = 0.200000
 - Momentum      = 0.500000
Network's size:
	Layer 0: 60 weights, 30 biases
	Layer 1: 600 weights, 20 biases
	Layer 2: 80 weights, 4 biases
	Total number of synapses: 794 (i.e. weights + biases)
---------------------------
Heuristics parameters:
- Init with random weights
- Select best weights at init
- Begin training on a subset of the dataset
- Slightly change weights if needed
- Variable learning rate (linear scale)
- Random variable Sigmoid gain
- Force weights less than 0.1500 to zero
- Gradient clipping (clip value 0.750)
- Prune inactive neurons at test phase
---------------------------
Sum of ratios is not 100% (600.0%): setting ratios to 0.67, 0.17, 0.17
Dataset split in: 200 train + 50 validation + 50 test data
Normalizing the dataset
Batch size = 10
Stopping if error < 0.040

Running optimization
Shuffling dataset...
Creating a new network
Searching best starting weights
--> Found better weights (error = 1.0100)
Estimated maximum duration : 4347.00 s for 150 epochs

Epoch 1 	Average error :   1.3000 (validation   1.7000)
Epoch 2 	Average error :   1.1500 (validation   1.7000)
...
Epoch 6 	Average error :   1.1000 (validation   1.7000)
Epoch 7 	Average error :   0.9750 (validation   1.7000)
..............
Epoch 22 	Average error :   0.9500 (validation   1.7000)
Now training on the entire dataset
Epoch 23 	Average error :   1.1000 (validation   0.8600)
Random change to weights (amplitude 2.5%)
Epoch 24 	Average error :   1.0200 (validation   0.4400)
Epoch 25 	Average error :   0.7800 (validation   0.4600)
Epoch 26 	Average error :   0.6650 (validation   0.4000)
Random change to weights (amplitude 2.5%)
Epoch 27 	Average error :   0.6000 (validation   0.2600)
Epoch 28 	Average error :   0.5300 (validation   0.2400)
Epoch 29 	Average error :   0.4550 (validation   0.1600)
Epoch 30 	Average error :   0.4000 (validation   0.1600)
Epoch 31 	Average error :   0.3500 (validation   0.1600)
Epoch 32 	Average error :   0.3250 (validation   0.1400)
Epoch 33 	Average error :   0.2950 (validation   0.1400)
Epoch 34 	Average error :   0.2850 (validation   0.1400)
Epoch 35 	Average error :   0.2750 (validation   0.1400)
Epoch 36 	Average error :   0.2350 (validation   0.1400)
Epoch 37 	Average error :   0.2150 (validation   0.1000)
...
Epoch 41 	Average error :   0.2050 (validation   0.1000)
..
Epoch 44 	Average error :   0.2000 (validation   0.1200)
Epoch 45 	Average error :   0.1850 (validation   0.1000)
..
Epoch 48 	Average error :   0.1750 (validation   0.1200)
Epoch 49 	Average error :   0.1700 (validation   0.1200)
Epoch 50 	Average error :   0.1650 (validation   0.1200)
Epoch 51 	Average error :   0.1600 (validation   0.1200)
...
Epoch 55 	Average error :   0.1550 (validation   0.1200)
......
Epoch 62 	Average error :   0.1450 (validation   0.1000)
Epoch 63 	Average error :   0.1400 (validation   0.0800)
..
Epoch 66 	Average error :   0.1200 (validation   0.0800)
............
Epoch 79 	Average error :   0.1150 (validation   0.0400)
...............Restoring last saved weights
...............
Epoch 110 	Average error :   0.1100 (validation   0.0400)
..........
Epoch 121 	Average error :   0.1050 (validation   0.0400)
........
Epoch 130 	Average error :   0.0950 (validation   0.0400)
.....Random change to weights (amplitude 2.5%)

Epoch 136 	Average error :   0.0850 (validation   0.0400)
....Random change to weights (amplitude 2.5%)
.
Epoch 142 	Average error :   0.0800 (validation   0.0400)
......Random change to weights (amplitude 2.5%)
..
Timer : 2138.62 s

Evaluation on test data (50 samples):
 - Minimum value of error :   0.0000
 - Maximum value of error :   1.0000
 - Mean value of error    :   0.0200
 - Std deviation of error :   0.1400
 - L1 norm of error       :   1.0000
 - L2 norm of error       :   1.0000
Confusion matrix:
TR/PR    0    1    2    3  (Recall)
  0 :   10    0    0    0  (100.0%)
  1 :    1    9    0    0  ( 90.0%)
  2 :    0    0   14    0  (100.0%)
  3 :    0    0    0   16  (100.0%)
Prec:   91% 100% 100% 100%
Low precision prediction :  10.0%
Average test error  :   0.0200
---------------------------
Attempting to prune the network...
Pruning inactive neurons
Layer 0 : neuron 0 is inactive
Layer 0 : neuron 2 is inactive
Layer 0 : neuron 3 is inactive
Layer 0 : neuron 6 is inactive
Layer 0 : neuron 9 is inactive
Layer 0 : neuron 12 is inactive
Layer 0 : neuron 15 is inactive
Layer 0 : neuron 16 is inactive
Layer 0 : neuron 19 is inactive
Layer 0 : neuron 21 is inactive
Layer 0 : neuron 23 is inactive
Layer 0 : neuron 25 is inactive
Pruning neurons with low activity
Layer 1 : neuron 1 can be pruned (13)
Layer 1 : neuron 6 can be pruned (13)
Succesfully pruned 14 neurons.
Network now has 472 synapses (-40.55%)

New evaluation on test data after pruning:
 - Minimum value of error :   0.0000
 - Maximum value of error :   2.0000
 - Mean value of error    :   0.0800
 - Std deviation of error :   0.3370
 - L1 norm of error       :   2.0000
 - L2 norm of error       :   2.4495
Confusion matrix:
TR/PR    0    1    2    3  (Recall)
  0 :   10    0    0    0  (100.0%)
  1 :    0   10    0    0  (100.0%)
  2 :    0    0   12    2  ( 85.7%)
  3 :    0    1    0   15  ( 93.8%)
Prec:  100%  91% 100%  88%
Low precision prediction :   4.0%
Average test error  :   0.0800
Saving network in file /SectorNetwork.txt

Verification:
Validation  0: expected 2, prediction 2 -->OK
Validation  1: expected 0, prediction 0 -->OK
Validation  2: expected 3, prediction 3 -->OK
Validation  3: expected 1, prediction 1 -->OK
Validation  4: expected 1, prediction 1 -->OK
Validation  5: expected 1, prediction 0 -->NOK
Validation  6: expected 3, prediction 3 -->OK
Validation  7: expected 3, prediction 3 -->OK
Validation  8: expected 0, prediction 0 -->OK
Validation  9: expected 2, prediction 2 -->OK
Validation 10: expected 3, prediction 3 -->OK
Validation 11: expected 1, prediction 1 -->OK
Validation 12: expected 2, prediction 2 -->OK
Validation 13: expected 0, prediction 0 -->OK
Validation 14: expected 1, prediction 1 -->OK
Validation 15: expected 0, prediction 0 -->OK
Validation 16: expected 1, prediction 1 -->OK
Validation 17: expected 2, prediction 2 -->OK
Validation 18: expected 0, prediction 0 -->OK
Validation 19: expected 1, prediction 0 -->NOK
Mean classification rate : 90.00 %

---------------------------
Network has 4 layers:
Layer 0: 2 neurons
Layer 1: 18 neurons, activation SIGMOID, 36 weights, 18 biases
Layer 2: 18 neurons, activation SIGMOID, 324 weights, 18 biases
Layer 3: 4 neurons, activation SOFTMAX, 72 weights, 4 biases
Total number of synapses: 472 (i.e. weights + biases)
Average L1 norm of synapses: 0.507764
Average L2 norm of synapses: 0.561365
Average value of synapses:   -0.127509
Standard dev. of synapses:   1.051890
Ratio of synapses greater than 1:   18.01 %
Ratio of synapses less than 1:      23.09 %
Ratio of synapses less than 0.1:     0.00 %
Ratio of synapses less than 0.01:    0.00 %
Ratio of synapses less than 0.001:   0.00 %
Ratio of synapses less than 0.0001: 58.90 % (sparsity)

Final learning rate: 0.200000
Final Sigmoid gain : 1.000000
Final momentum     : 0.500000
---------------------------
