Adding:
  Net.setHeurZeroWeights(true, 0.20);
  Net.setHeurPruning(true, 0.80);
before:
  Net.displayHeuristics();

Verbose level : 1
Creating network:
4 layers
	Input layer: 2 neurons
	Hidden layer 1: 30 neurons
	Hidden layer 2: 20 neurons
	Output layer: 4 neurons
Processing dataset
Setting activations:
	Layer 0: activation SIGMOID
	Layer 1: activation SIGMOID
	Layer 2: activation SOFTMAX
Setting hyperparameters:
 - Learning rate = 0.200000
 - Momentum      = 0.500000
Network's size:
	Layer 0: 60 weights, 30 biases
	Layer 1: 600 weights, 20 biases
	Layer 2: 80 weights, 4 biases
	Total number of synapses: 794 (i.e. weights + biases)
---------------------------
Heuristics parameters:
- Init with random weights
- Select best weights at init
- Begin training on a subset of the dataset
- Slightly change weights if needed
- Variable learning rate (linear scale)
- Random variable Sigmoid gain
- Force weights less than 0.200 to zero
- Gradient clipping (clip value 0.750)
- Prune inactive neurons during training phase
- Prune inactive or low activity neurons at test phase
---------------------------
Sum of ratios is not 100% (600.0%): setting ratios to 0.67, 0.17, 0.17
Dataset split in: 200 train + 50 validation + 50 test data
Normalizing the dataset
Batch size = 10
Stopping if error < 0.040

Running optimization
Shuffling dataset...
Creating a new network
Searching best starting weights
--> Found better weights (error = 0.9200)
--> Found better weights (error = 0.8600)
Estimated maximum duration : 3717.00 s for 150 epochs

Epoch 1 	Average error :   1.1500 (validation   1.5000)
Epoch 2 	Average error :   1.1250 (validation   0.9000)
Epoch 3 	Average error :   0.9250 (validation   0.9000)
............Heuristics: changing Sigmoid gain to 1.15
...Restoring last saved weights
.........Heuristics: changing Sigmoid gain to 1.15
......Heuristics: changing Sigmoid gain to 1.30

Epoch 34 	Average error :   0.8250 (validation   1.0000)
Epoch 35 	Average error :   0.8000 (validation   1.0000)
Now training on the entire dataset
Epoch 36 	Average error :   0.9350 (validation   1.0000)
Epoch 37 	Average error :   0.8450 (validation   0.9800)
Epoch 38 	Average error :   0.7600 (validation   0.9000)
Epoch 39 	Average error :   0.6450 (validation   0.7000)
Epoch 40 	Average error :   0.4500 (validation   0.5400)
Epoch 41 	Average error :   0.3150 (validation   0.3000)
Epoch 42 	Average error :   0.2850 (validation   0.2000)
Epoch 43 	Average error :   0.2100 (validation   0.2200)
Epoch 44 	Average error :   0.1850 (validation   0.2200)
Epoch 45 	Average error :   0.1400 (validation   0.2200)
Pruning inactive neurons
Layer 1 : neuron 3 is inactive
Layer 1 : neuron 10 is inactive
Layer 1 : neuron 14 is inactive
Layer 1 : neuron 15 is inactive
Layer 1 : neuron 18 is inactive
Layer 1 : neuron 23 is inactive
Layer 1 : neuron 26 is inactive
Succesfully pruned 7 neurons
Network's size:
	Layer 0: 46 weights, 23 biases
	Layer 1: 460 weights, 20 biases
	Layer 2: 80 weights, 4 biases
	Total number of synapses: 633 (i.e. weights + biases)
.
Epoch 47 	Average error :   0.1000 (validation   0.2200)
...
Epoch 51 	Average error :   0.0950 (validation   0.2200)
Epoch 52 	Average error :   0.0900 (validation   0.1800)
...............Restoring last saved weights
................Restoring last saved weights
Random change to weights (amplitude 10.0%)
................Restoring last saved weights
......Random change to weights (amplitude 2.5%)
..........Restoring last saved weights
................Restoring last saved weights
Random change to weights (amplitude 10.0%)
................Restoring last saved weights
...
Timer : 1683.79 s

Evaluation on test data (50 samples):
 - Minimum value of error :   0.0000
 - Maximum value of error :   2.0000
 - Mean value of error    :   0.1200
 - Std deviation of error :   0.4308
 - L1 norm of error       :   2.0000
 - L2 norm of error       :   3.1623
Confusion matrix:
TR/PR    0    1    2    3  (Recall)
  0 :   13    0    0    0  (100.0%)
  1 :    0   10    0    0  (100.0%)
  2 :    1    0    9    2  ( 75.0%)
  3 :    0    1    0   14  ( 93.3%)
Prec:   93%  91% 100%  88%
Low precision prediction :  10.0%
Average test error  :   0.1200
---------------------------
Attempting to prune the network...
Pruning inactive neurons
No inactive neuron found.
Pruning neurons with low activity
Layer 2 : neuron 2 can be pruned (19)
Layer 2 : neuron 8 can be pruned (18)
Layer 2 : neuron 19 can be pruned (18)
Succesfully pruned 3 neurons.
Network now has 549 synapses (-13.27%)

New evaluation on test data after pruning:
 - Minimum value of error :   0.0000
 - Maximum value of error :   2.0000
 - Mean value of error    :   0.3800
 - Std deviation of error :   0.7181
 - L1 norm of error       :   2.0000
 - L2 norm of error       :   5.7446
Confusion matrix:
TR/PR    0    1    2    3  (Recall)
  0 :   13    0    0    0  (100.0%)
  1 :    0   10    0    0  (100.0%)
  2 :    4    0    3    5  ( 25.0%)
  3 :    0    3    0   12  ( 80.0%)
Prec:   76%  77% 100%  71%
Low precision prediction :  18.0%
Average test error  :   0.3800
Saving network in file /SectorNetwork.txt

Verification:
Validation  0: expected 0, prediction 0 -->OK
Validation  1: expected 2, prediction 2 -->OK
Validation  2: expected 2, prediction 0 -->NOK
Validation  3: expected 1, prediction 1 -->OK
Validation  4: expected 2, prediction 2 -->OK
Validation  5: expected 3, prediction 3 -->OK
Validation  6: expected 3, prediction 3 -->OK
Validation  7: expected 2, prediction 3 -->NOK
Validation  8: expected 3, prediction 3 -->OK
Validation  9: expected 0, prediction 0 -->OK
Validation 10: expected 2, prediction 2 -->OK
Validation 11: expected 2, prediction 2 -->OK
Validation 12: expected 2, prediction 2 -->OK
Validation 13: expected 1, prediction 1 -->OK
Validation 14: expected 0, prediction 0 -->OK
Validation 15: expected 2, prediction 2 -->OK
Validation 16: expected 3, prediction 3 -->OK
Validation 17: expected 0, prediction 0 -->OK
Validation 18: expected 1, prediction 1 -->OK
Validation 19: expected 1, prediction 1 -->OK
Mean classification rate : 90.00 %

---------------------------
Network has 4 layers:
Layer 0: 2 neurons
Layer 1: 23 neurons, activation SIGMOID, 46 weights, 23 biases
Layer 2: 17 neurons, activation SIGMOID, 391 weights, 17 biases
Layer 3: 4 neurons, activation SOFTMAX, 68 weights, 4 biases
Total number of synapses: 549 (i.e. weights + biases)
Average L1 norm of synapses: 0.410591
Average L2 norm of synapses: 0.299690
Average value of synapses:   -0.036021
Standard dev. of synapses:   0.773358
Ratio of synapses greater than 1:   16.94 %
Ratio of synapses less than 1:      22.95 %
Ratio of synapses less than 0.1:     0.00 %
Ratio of synapses less than 0.01:    0.00 %
Ratio of synapses less than 0.001:   0.00 %
Ratio of synapses less than 0.0001: 60.11 % (sparsity)

Final learning rate: 0.200000
Final Sigmoid gain : 1.300000
Final momentum     : 0.500000
---------------------------
